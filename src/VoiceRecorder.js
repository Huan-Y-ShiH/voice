import React, { useState, useRef, useEffect } from 'react';
import './VoiceRecorder.css';
import { Link } from 'react-router-dom';

export const textToSpeech = async (text) => {
  try {
    const response = await fetch('https://www.srtp.site:8080/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    });

    if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);

    const blob = await response.blob();
    const audioUrl = URL.createObjectURL(blob);
    const audio = new Audio(audioUrl);
    
    audio.onended = () => URL.revokeObjectURL(audioUrl);
    const playPromise = audio.play();
    
    if (playPromise !== undefined) {
      playPromise.catch(err => console.log("æ’­æ”¾ä¸­æ–­:", err));
    }
  } catch (error) {
    console.error("æ–‡å­—è½¬è¯­éŸ³é”™è¯¯:", error);
    alert("è¯­éŸ³è½¬æ¢å¤±è´¥ï¼Œè¯·é‡è¯•");
  }
};

const VoiceRecorder = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [inputText, setInputText] = useState('');
  const [transcriptionHistory, setTranscriptionHistory] = useState([]);
  const [browserSupport, setBrowserSupport] = useState(true);
  const [isPlaying, setIsPlaying] = useState(false);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);
  const streamRef = useRef(null);
  const audioRef = useRef(null); // æ–°å¢ï¼šç®¡ç†éŸ³é¢‘å¯¹è±¡

  // å¢å¼ºç‰ˆæµè§ˆå™¨å…¼å®¹æ€§æ£€æŸ¥
  useEffect(() => {
    const checkCompatibility = async () => {
      try {
        const isSupported = (
          navigator.mediaDevices && 
          window.MediaRecorder &&
          typeof MediaRecorder === 'function' &&
          typeof MediaRecorder.isTypeSupported === 'function'
        );
        
        // å®é™…æµ‹è¯•MediaRecorderåŠŸèƒ½
        if (isSupported) {
          const testStream = await navigator.mediaDevices.getUserMedia({ audio: true }).catch(() => null);
          if (testStream) {
            try {
              const testRecorder = new MediaRecorder(testStream);
              if (typeof testRecorder.start !== 'function') {
                throw new Error('MediaRecorder API not functional');
              }
              testRecorder.start();
              testRecorder.stop();
              testStream.getTracks().forEach(track => track.stop());
            } catch (e) {
              console.error('MediaRecorder test failed:', e);
              throw e;
            }
          }
        }
        
        setBrowserSupport(isSupported);
        
        if (!isSupported) {
          alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨æœ€æ–°ç‰ˆChrome/Edge/Safariæµè§ˆå™¨');
        }
      } catch (error) {
        console.error('å…¼å®¹æ€§æ£€æŸ¥å‡ºé”™:', error);
        setBrowserSupport(false);
      }
    };
    
    checkCompatibility();
    
    // æ¸…ç†å‡½æ•°
    return () => {
      if (mediaRecorderRef.current?.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
      cleanupStream();
    };
  }, []);

  // æ”¹è¿›çš„å½•éŸ³å¯åŠ¨å‡½æ•°
  const startRecording = async () => {
    if (!browserSupport || isLoading) return;

    try {
      setTranscription('');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      }).catch(err => {
        console.error("éº¦å…‹é£æƒé™é”™è¯¯:", err);
        alert("è¯·å…è®¸éº¦å…‹é£æƒé™");
        return null;
      });

      if (!stream) return;
      
      // æ¸…ç†ä¹‹å‰çš„å½•éŸ³å™¨
      if (mediaRecorderRef.current?.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
      cleanupStream();

      streamRef.current = stream;

      // å¢å¼ºçš„MIMEç±»å‹æ£€æµ‹
      const getSupportedMimeType = () => {
        const types = [
          'audio/webm;codecs=opus',
          'audio/webm',
          'audio/mp4;codecs=mp4a',
          'audio/mp4',
          'audio/ogg;codecs=opus',
          'audio/wav',
          'audio/x-wav',
          ''
        ];
        return types.find(type => !type || MediaRecorder.isTypeSupported(type));
      };

      const mimeType = getSupportedMimeType();
      const options = mimeType ? { mimeType } : {};

      // åˆ›å»ºå½•éŸ³å™¨å®ä¾‹
      try {
        mediaRecorderRef.current = new MediaRecorder(stream, options);
        
        // æ£€æŸ¥æ˜¯å¦çœŸçš„åˆ›å»ºæˆåŠŸ
        if (typeof mediaRecorderRef.current.start !== 'function') {
          throw new Error('MediaRecorderåˆ›å»ºå¤±è´¥ï¼Œstartæ–¹æ³•ä¸å­˜åœ¨');
        }
      } catch (e) {
        console.error('MediaRecorderåˆå§‹åŒ–å¤±è´¥:', e);
        throw new Error('æ— æ³•åˆå§‹åŒ–å½•éŸ³å™¨');
      }

      chunksRef.current = [];
      
      mediaRecorderRef.current.ondataavailable = (e) => {
        if (e.data.size > 0) chunksRef.current.push(e.data);
      };

      mediaRecorderRef.current.onstop = async () => {
        try {
          const blob = new Blob(chunksRef.current, { 
            type: mediaRecorderRef.current.mimeType || 'audio/wav'
          });
          await uploadAudio(blob);
        } catch (error) {
          console.error('å½•éŸ³å¤„ç†å‡ºé”™:', error);
        } finally {
          cleanupStream();
        }
      };

      mediaRecorderRef.current.onerror = (e) => {
        console.error('å½•éŸ³å™¨é”™è¯¯:', e.error);
        alert(`å½•éŸ³å‡ºé”™: ${e.error.message}`);
        cleanupStream();
      };

      // å¯åŠ¨å½•éŸ³ï¼ˆç§»é™¤timesliceå‚æ•°ç¡®ä¿å…¼å®¹æ€§ï¼‰
      mediaRecorderRef.current.start();
      setIsRecording(true);
    } catch (error) {
      console.error("å½•éŸ³å¯åŠ¨å¤±è´¥:", error);
      alert(`å½•éŸ³å¤±è´¥: ${error.message}`);
      setIsRecording(false);
      cleanupStream();
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    try {
      if (mediaRecorderRef.current?.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    } catch (error) {
      console.error('åœæ­¢å½•éŸ³å‡ºé”™:', error);
    } finally {
      setIsRecording(false);
    }
  };

  // æ¸…ç†åª’ä½“æµ
  const cleanupStream = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    chunksRef.current = [];
  };

  // ç»Ÿä¸€å½•éŸ³æŒ‰é’®å¤„ç†
  const handleRecordButton = (e) => {
    e.preventDefault();
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  // æ·»åŠ è½¬å½•ç»“æœåˆ°å†å²è®°å½•
  const addToHistory = (text, type = 'user') => {
    const newEntry = {
      id: Date.now(),
      text,
      type,
      timestamp: new Date().toLocaleTimeString(),
    };
    setTranscriptionHistory(prev => [...prev, newEntry]);
  };

  // å¤„ç†æ–‡æœ¬è¾“å…¥å˜åŒ–
  const handleInputChange = (e) => {
    setInputText(e.target.value);
  };
  
  // å¤„ç†æ–‡æœ¬æäº¤
  const handleTextSubmit = async (e) => {
    e.preventDefault();
    if (!inputText.trim()) return;

    const text = inputText.trim();
    addToHistory(text, 'assistant');
    await textToSpeech(text);
    setInputText('');
  };

  // ä¸FastAPIæ¥å£é€šä¿¡
  const sendToFastAPI = async (text) => {
    try {
      const response = await fetch('https://www.srtp.site:8080/api/transcribe', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer sk-abcdef',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ text })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      if (result && result.response) {
        await textToSpeech(result.response);
      }
    } catch (error) {
      console.error("Error communicating with FastAPI:", error);
    }
  };

  // ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶è¯·æ±‚è½¬å½•
  const uploadAudio = async (audioBlob) => {
    setIsLoading(true);
    const formData = new FormData();
    formData.append("model", "FunAudioLLM/SenseVoiceSmall");
    formData.append("file", audioBlob, "recording.wav");

    try {
      const response = await fetch('https://api.siliconflow.cn/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer sk-fbvnyezvojrfaypxcnrqsmwyxpmvfkpnlelhmprqzdzeawci'
        },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      if (result && result.text) {
        setTranscription(result.text);
        await sendToFastAPI(result.text);
      } else {
        throw new Error('No transcription in response');
      }
    } catch (error) {
      console.error("Error uploading audio:", error);
      setTranscription('è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•');
    } finally {
      setIsLoading(false);
    }
  };
  
  return (
    <div className="voice-recorder">
      <form onSubmit={handleTextSubmit} className="text-input-form">
        <input
          type="text"
          value={inputText}
          onChange={handleInputChange}
          placeholder="è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³..."
        />
        <button 
          type="submit" 
          disabled={!inputText.trim()}
          className="send-button"
        >
          å‘é€
        </button>
      </form>

      <div className="controls">
        <button 
          onClick={handleRecordButton}
          onTouchEnd={handleRecordButton}
          className={isRecording ? 'recording' : ''}
          disabled={isLoading || !browserSupport}
        >
          {isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
        </button>
        
        <Link to="/auto-listener" className="mode-switch-button">
          ç›‘å¬æ¨¡å¼
        </Link>
      </div>

      {isLoading && (
        <div className="loading">
          æ­£åœ¨è½¬å½•ä¸­...
        </div>
      )}

      <div className="chat-history">
        {transcriptionHistory.map((entry) => (
          <div key={entry.id} className={`chat-message ${entry.type}`}>
            <div className="message-content">
              <p>{entry.text}</p>
              <span className="timestamp">{entry.timestamp}</span>
            </div>
            {entry.type === 'assistant' && (
              <div className="message-actions">
                <button 
                  className={`replay-button ${isPlaying ? 'playing' : ''}`}
                  onClick={() => textToSpeech(entry.text)}
                  title="é‡æ–°æ’­æ”¾"
                  disabled={isPlaying}
                >
                  {isPlaying ? 'ğŸ”Š' : 'ğŸ”ˆ'}
                </button>
              </div>
            )}
          </div>
        ))}
      </div>

      {transcription && (
        <div className="transcription">
          <div className="transcription-content">
            <div className="transcription-text">
              <p>{transcription}</p>
            </div>
            <button 
              className="confirm-button"
              onClick={() => {
                addToHistory(transcription, 'user');
                setTranscription('');
              }}
            >
              ç¡®è®¤
            </button>
          </div>
        </div>
      )}
    </div>
  );
};

export default VoiceRecorder;