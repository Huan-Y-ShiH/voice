import React, { useState, useRef } from 'react';
import './VoiceRecorder.css';

import { Link } from 'react-router-dom';


const VoiceRecorder = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [_audioUrl, setAudioUrl] = useState(null);
  const [transcription, setTranscription] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [inputText, setInputText] = useState('');
  const [transcriptionHistory, setTranscriptionHistory] = useState([]);
  const [isPlaying, setIsPlaying] = useState(false);
  const _audioRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);

  // æ·»åŠ è½¬å½•ç»“æœåˆ°å†å²è®°å½•
  const addToHistory = (text, type = 'user') => {
    const newEntry = {
      id: Date.now(),
      text,
      type,
      timestamp: new Date().toLocaleTimeString(),
    };
    setTranscriptionHistory(prev => [...prev, newEntry]);
  };

  // å¤„ç†æ–‡æœ¬è¾“å…¥å˜åŒ–
  const handleInputChange = (e) => {
    setInputText(e.target.value);
  };
  // å¤„ç†æ–‡æœ¬æäº¤
  const handleTextSubmit = async (e) => {
    e.preventDefault();
    if (!inputText.trim()) return;

    const text = inputText.trim();
    // æ·»åŠ åˆ°å†å²è®°å½•ï¼ˆä½œä¸ºå¯¹è¯è€…çš„æ¶ˆæ¯ï¼‰
    addToHistory(text, 'assistant');
    // è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾
    await textToSpeech(text);
    // æ¸…ç©ºè¾“å…¥æ¡†
    setInputText('');
  };

  // ä¸FastAPIæ¥å£é€šä¿¡
  const sendToFastAPI = async (text) => {
    try {
      const response = await fetch('https://www.srtp.site:8080/api/transcribe', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer sk-abcdef',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ text })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      if (result && result.response) {

        // ä½¿ç”¨FastAPIçš„å“åº”è¿›è¡Œæ–‡å­—è½¬è¯­éŸ³
        await textToSpeech(result.response);

      }
    } catch (error) {
      console.error("Error communicating with FastAPI:", error);
    }
  };

  // æ–‡å­—è½¬è¯­éŸ³
  const textToSpeech = async (text) => {
    try {
      setIsPlaying(true);
      const response = await fetch('https://www.srtp.site:8080/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text: text
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const blob = await response.blob();
      const audioUrl = URL.createObjectURL(blob);
      
      const audio = new Audio(audioUrl);
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
        setIsPlaying(false);
      };
      
      await audio.play();
      
    } catch (error) {
      console.error("æ–‡å­—è½¬è¯­éŸ³é”™è¯¯:", error);
      alert("è¯­éŸ³è½¬æ¢å¤±è´¥ï¼Œè¯·é‡è¯•");
      setIsPlaying(false);
    }
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    try {
      setTranscription('');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorderRef.current = new MediaRecorder(stream);
      chunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioUrl(audioUrl);
        uploadAudio(audioBlob);
      };

      mediaRecorderRef.current.start();
      setIsRecording(true);
    } catch (error) {
      console.error("Error starting recording:", error);
      alert("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆéº¦å…‹é£æƒé™ã€‚");
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      setIsRecording(false);
    }
  };

  // ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¹¶è¯·æ±‚è½¬å½•
  const uploadAudio = async (audioBlob) => {
    setIsLoading(true);
    const formData = new FormData();
    formData.append("model", "FunAudioLLM/SenseVoiceSmall");
    formData.append("file", audioBlob, "recording.wav");

    try {
      const response = await fetch('https://api.siliconflow.cn/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer sk-fbvnyezvojrfaypxcnrqsmwyxpmvfkpnlelhmprqzdzeawci'
        },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const result = await response.json();
      if (result && result.text) {
        setTranscription(result.text);

        // å°†è½¬å½•ç»“æœå‘é€åˆ°FastAPI
        await sendToFastAPI(result.text);


      } else {
        throw new Error('No transcription in response');
      }
    } catch (error) {
      console.error("Error uploading audio:", error);
      setTranscription('è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•');
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="voice-recorder">
      <form onSubmit={handleTextSubmit} className="text-input-form">
        <input
          type="text"
          value={inputText}
          onChange={handleInputChange}
          placeholder="è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³..."
          disabled={isPlaying}
        />
        <button 
          type="submit" 
          disabled={!inputText.trim() || isPlaying}
          className="send-button"
        >
          å‘é€
        </button>
      </form>

      <div className="controls">
        <button 
          onClick={isRecording ? stopRecording : startRecording}
          className={isRecording ? 'recording' : ''}
          disabled={isLoading || isPlaying}
        >
          {isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
        </button>
        

        <Link to="/auto-listener" className="mode-switch-button">
          ç›‘å¬æ¨¡å¼
        </Link>


      </div>

      {isLoading && (
        <div className="loading">
          æ­£åœ¨è½¬å½•ä¸­...
        </div>
      )}

      <div className="chat-history">
        {transcriptionHistory.map((entry) => (
          <div key={entry.id} className={`chat-message ${entry.type}`}>
            <div className="message-content">
              <p>{entry.text}</p>
              <span className="timestamp">{entry.timestamp}</span>
            </div>
            {entry.type === 'assistant' && (
              <div className="message-actions">
                <button 
                  className={`replay-button ${isPlaying ? 'playing' : ''}`}
                  onClick={() => textToSpeech(entry.text)}
                  title="é‡æ–°æ’­æ”¾"
                  disabled={isPlaying}
                >
                  {isPlaying ? 'ğŸ”Š' : 'ğŸ”ˆ'}
                </button>
              </div>
            )}
          </div>
        ))}
      </div>

      {transcription && (
        <div className="transcription">
          <div className="transcription-content">
            <div className="transcription-text">
              <p>{transcription}</p>
            </div>
            <button 
              className="confirm-button"
              onClick={() => {
                addToHistory(transcription, 'user');
                setTranscription('');
              }}
            >
              ç¡®è®¤
            </button>
          </div>
        </div>
      )}
    </div>
  );
};

export default VoiceRecorder;
